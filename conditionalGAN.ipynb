{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sim2real\\AppData\\Local\\miniconda3\\envs\\fish\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time \n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "from  torchinfo import summary \n",
    "import torchsummary\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setting \n",
    "EPOCHS = 200 \n",
    "BATCH_SIZE = 100 \n",
    "LEARNING_RATE = 0.0002\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_CHANNEL = 1 \n",
    "LATENT_DIM = 100 # 28*28 = 784가 아닌데?\n",
    "\n",
    "DIRECTORY_NAME = \"./ConditionalGAN_Result\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device {DEVICE}\")\n",
    "# Result Directory \n",
    "if not os.path.exists(DIRECTORY_NAME):\n",
    "    os.makedirs(DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data path: ./dataset/Fashion-MNIST/fashion-mnist_train.csv\n",
      "Valid data path: ./dataset/Fashion-MNIST/fashion-mnist_test.csv\n",
      "Image size: (60000, 28, 28)\n",
      "--- Label ---\n",
      "label\n",
      "2    6000\n",
      "9    6000\n",
      "6    6000\n",
      "0    6000\n",
      "3    6000\n",
      "4    6000\n",
      "5    6000\n",
      "8    6000\n",
      "7    6000\n",
      "1    6000\n",
      "Name: count, dtype: int64\n",
      "<PIL.Image.Image image mode=L size=28x28 at 0x1CAA1B667F0>\n",
      "Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "train_data_path = './dataset/Fashion-MNIST/fashion-mnist_train.csv' # Path of data\n",
    "valid_data_path = './dataset/Fashion-MNIST/fashion-mnist_test.csv' # Path of data\n",
    "print('Train data path:', train_data_path)\n",
    "print('Valid data path:', valid_data_path)\n",
    "\n",
    "class_list = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_num = len(class_list)\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "\n",
    "class FashionMNIST(Dataset):\n",
    "    def __init__(self, path, img_size, transform=None):\n",
    "        self.transform = transform\n",
    "        fashion_df = pd.read_csv(path)\n",
    "        self.images = fashion_df.iloc[:, 1:].values.astype('uint8').reshape(-1, img_size, img_size)\n",
    "        self.labels = fashion_df.label.values\n",
    "        print('Image size:', self.images.shape)\n",
    "        print('--- Label ---')\n",
    "        print(fashion_df.label.value_counts())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = self.images[idx]\n",
    "        img = Image.fromarray(self.images[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "\n",
    "\n",
    "dataset = FashionMNIST(train_data_path, IMAGE_SIZE,transform=None)\n",
    "imshow(dataset[1][0])\n",
    "print(dataset[1][0])\n",
    "print(class_list[dataset[1][1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (60000, 28, 28)\n",
      "--- Label ---\n",
      "label\n",
      "2    6000\n",
      "9    6000\n",
      "6    6000\n",
      "0    6000\n",
      "3    6000\n",
      "4    6000\n",
      "5    6000\n",
      "8    6000\n",
      "7    6000\n",
      "1    6000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = FashionMNIST(train_data_path,IMAGE_SIZE,transform=transforms_train)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator,self).__init__()\n",
    "    \n",
    "        self.linear_layer = []\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(IMAGE_CHANNEL*IMAGE_SIZE*IMAGE_SIZE+class_num,1024),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x,labels):\n",
    "        x = x.view(BATCH_SIZE,IMAGE_SIZE*IMAGE_SIZE*IMAGE_CHANNEL)\n",
    "        label = F.one_hot(labels, num_classes=class_num)\n",
    "        real_image_label = torch.cat([x,label],1)\n",
    "        out = self.model(real_image_label)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "discriminator = Discriminator().to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Generator,self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM+class_num,256),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(256,512),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(1024,IMAGE_CHANNEL*IMAGE_SIZE*IMAGE_SIZE),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,z,labels):\n",
    "        z = z.view(-1,LATENT_DIM)\n",
    "        c = F.one_hot(labels,num_classes=class_num)\n",
    "        # print(z.size(),c.size())\n",
    "        x = torch.cat([z,c],1)\n",
    "        out = self.model(x)\n",
    "        return out.view(-1,IMAGE_CHANNEL,IMAGE_SIZE,IMAGE_SIZE)\n",
    "    \n",
    "generator = Generator().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# for epoch in range(EPOCHS):\n",
    "#     #print('Starting epoch {}...'.format(epoch+1))\n",
    "#     for i,(images,labels) in enumerate(data_loader):\n",
    "#         real_imgs = images.to(DEVICE)\n",
    "#         real_labels = labels.to(DEVICE)\n",
    "\n",
    "#         discriminator_label = torch.cuda.FloatTensor(BATCH_SIZE,1).fill_(1.0)\n",
    "#         generator_label =torch.cuda.FloatTensor(BATCH_SIZE,1).fill_(0.0)\n",
    "#         # discriminator Train \n",
    "#         d_optimizer.zero_grad()\n",
    "#         real_validity = discriminator(real_imgs,real_labels)\n",
    "#         D_loss = adversarial_loss(real_validity,discriminator_label)\n",
    "\n",
    "#         latent_vector = torch.normal(mean = 0,std =1,size=(BATCH_SIZE,LATENT_DIM)).to(DEVICE)\n",
    "#         fake_labels = torch.LongTensor(np.random.randint(0,class_num,BATCH_SIZE)).to(DEVICE)\n",
    "\n",
    "#         fake_images = generator(latent_vector,fake_labels)\n",
    "#         #print(fake_images.size())\n",
    "#         G_loss = adversarial_loss(discriminator(fake_images.detach(),fake_labels),generator_label)\n",
    "\n",
    "#         t_loss = (D_loss + G_loss) /2 \n",
    "#         t_loss.backward()\n",
    "#         d_optimizer.step()\n",
    "\n",
    "#         g_optimizer.zero_grad()\n",
    "#         fake_images = generator(latent_vector,fake_labels)\n",
    "#         G_loss = adversarial_loss(discriminator(fake_images,fake_labels),discriminator_label)\n",
    "#         G_loss.backward()\n",
    "#         g_optimizer.step()\n",
    "#         done = epoch* len(data_loader)+i\n",
    "#         if done % 12000 == 0:\n",
    "#             save_image(fake_images.data[:9],f\"{DIRECTORY_NAME}/{epoch}_epoch.png\",nrow = 3,normalize = True)\n",
    "\n",
    "#     generator.eval()\n",
    "\n",
    "#     print(f\"[Epoch {epoch}/{EPOCHS}] [D loss:{t_loss.item():.6f}] [G loss: {G_loss.item():.6f}]\\\n",
    "#           [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
    "#     if epoch % 10 == 0:\n",
    "#         latent_vector = torch.normal(mean = 0,std =1,size=(class_num-1,LATENT_DIM)).to(DEVICE)\n",
    "#         labels =torch.LongTensor(np.arange(0,class_num-1)).to(DEVICE) # 0~9까지 순차적으로 형성된 라벨 \n",
    "#         sample_images = generator(latent_vector, labels).data.cpu()\n",
    "#         print(labels)\n",
    "#         save_image(sample_images.data[:],f\"{DIRECTORY_NAME}/{epoch}_epoch.png\",nrow = 3,normalize = True)\n",
    "\n",
    "# # fake_label을 전혀 사용하지 않고 작성해 보자 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss:0.087845] [G loss: 4.819378]          [Elapsed time: 13.90s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 1/200] [D loss:0.370737] [G loss: 2.682072]          [Elapsed time: 26.41s]\n",
      "[Epoch 2/200] [D loss:0.095889] [G loss: 3.582614]          [Elapsed time: 39.41s]\n",
      "[Epoch 3/200] [D loss:0.217362] [G loss: 3.220568]          [Elapsed time: 52.25s]\n",
      "[Epoch 4/200] [D loss:0.265066] [G loss: 2.945384]          [Elapsed time: 64.99s]\n",
      "[Epoch 5/200] [D loss:0.400218] [G loss: 2.467254]          [Elapsed time: 77.56s]\n",
      "[Epoch 6/200] [D loss:0.438059] [G loss: 2.172454]          [Elapsed time: 89.99s]\n",
      "[Epoch 7/200] [D loss:0.422760] [G loss: 1.613439]          [Elapsed time: 102.87s]\n",
      "[Epoch 8/200] [D loss:0.352496] [G loss: 1.769679]          [Elapsed time: 115.65s]\n",
      "[Epoch 9/200] [D loss:0.341933] [G loss: 1.822399]          [Elapsed time: 128.13s]\n",
      "[Epoch 10/200] [D loss:0.428327] [G loss: 1.583353]          [Elapsed time: 140.62s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 11/200] [D loss:0.553895] [G loss: 1.483094]          [Elapsed time: 153.17s]\n",
      "[Epoch 12/200] [D loss:0.414420] [G loss: 1.683669]          [Elapsed time: 165.67s]\n",
      "[Epoch 13/200] [D loss:0.480997] [G loss: 1.652024]          [Elapsed time: 178.04s]\n",
      "[Epoch 14/200] [D loss:0.353415] [G loss: 1.893881]          [Elapsed time: 190.48s]\n",
      "[Epoch 15/200] [D loss:0.369355] [G loss: 2.050071]          [Elapsed time: 202.97s]\n",
      "[Epoch 16/200] [D loss:0.486162] [G loss: 1.788311]          [Elapsed time: 215.41s]\n",
      "[Epoch 17/200] [D loss:0.387596] [G loss: 1.286316]          [Elapsed time: 227.90s]\n",
      "[Epoch 18/200] [D loss:0.377009] [G loss: 1.520479]          [Elapsed time: 240.40s]\n",
      "[Epoch 19/200] [D loss:0.552225] [G loss: 1.628776]          [Elapsed time: 253.21s]\n",
      "[Epoch 20/200] [D loss:0.532590] [G loss: 1.189851]          [Elapsed time: 266.48s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 21/200] [D loss:0.566339] [G loss: 1.340456]          [Elapsed time: 279.47s]\n",
      "[Epoch 22/200] [D loss:0.551906] [G loss: 1.485168]          [Elapsed time: 292.13s]\n",
      "[Epoch 23/200] [D loss:0.463250] [G loss: 1.334226]          [Elapsed time: 304.65s]\n",
      "[Epoch 24/200] [D loss:0.657225] [G loss: 1.059017]          [Elapsed time: 317.44s]\n",
      "[Epoch 25/200] [D loss:0.457398] [G loss: 1.545025]          [Elapsed time: 329.98s]\n",
      "[Epoch 26/200] [D loss:0.533477] [G loss: 1.303823]          [Elapsed time: 342.38s]\n",
      "[Epoch 27/200] [D loss:0.552799] [G loss: 1.458963]          [Elapsed time: 354.73s]\n",
      "[Epoch 28/200] [D loss:0.503912] [G loss: 1.455324]          [Elapsed time: 367.13s]\n",
      "[Epoch 29/200] [D loss:0.551372] [G loss: 1.356018]          [Elapsed time: 379.56s]\n",
      "[Epoch 30/200] [D loss:0.470409] [G loss: 1.338931]          [Elapsed time: 392.05s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 31/200] [D loss:0.464075] [G loss: 1.395218]          [Elapsed time: 404.55s]\n",
      "[Epoch 32/200] [D loss:0.513608] [G loss: 1.246005]          [Elapsed time: 417.36s]\n",
      "[Epoch 33/200] [D loss:0.502989] [G loss: 1.455360]          [Elapsed time: 430.41s]\n",
      "[Epoch 34/200] [D loss:0.487160] [G loss: 1.463374]          [Elapsed time: 443.14s]\n",
      "[Epoch 35/200] [D loss:0.619187] [G loss: 0.991155]          [Elapsed time: 455.74s]\n",
      "[Epoch 36/200] [D loss:0.555863] [G loss: 1.342809]          [Elapsed time: 468.45s]\n",
      "[Epoch 37/200] [D loss:0.608722] [G loss: 1.058476]          [Elapsed time: 480.84s]\n",
      "[Epoch 38/200] [D loss:0.527998] [G loss: 1.482613]          [Elapsed time: 493.29s]\n",
      "[Epoch 39/200] [D loss:0.427712] [G loss: 1.218364]          [Elapsed time: 505.77s]\n",
      "[Epoch 40/200] [D loss:0.423777] [G loss: 1.339191]          [Elapsed time: 518.32s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 41/200] [D loss:0.554619] [G loss: 1.066829]          [Elapsed time: 531.42s]\n",
      "[Epoch 42/200] [D loss:0.608135] [G loss: 1.030643]          [Elapsed time: 544.42s]\n",
      "[Epoch 43/200] [D loss:0.493423] [G loss: 1.229252]          [Elapsed time: 557.26s]\n",
      "[Epoch 44/200] [D loss:0.559586] [G loss: 1.265528]          [Elapsed time: 570.16s]\n",
      "[Epoch 45/200] [D loss:0.584741] [G loss: 1.095487]          [Elapsed time: 582.65s]\n",
      "[Epoch 46/200] [D loss:0.577677] [G loss: 1.164423]          [Elapsed time: 595.05s]\n",
      "[Epoch 47/200] [D loss:0.557319] [G loss: 1.312614]          [Elapsed time: 607.47s]\n",
      "[Epoch 48/200] [D loss:0.578694] [G loss: 1.043601]          [Elapsed time: 619.95s]\n",
      "[Epoch 49/200] [D loss:0.471225] [G loss: 1.330852]          [Elapsed time: 632.38s]\n",
      "[Epoch 50/200] [D loss:0.518853] [G loss: 1.302433]          [Elapsed time: 644.87s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 51/200] [D loss:0.593143] [G loss: 1.050807]          [Elapsed time: 657.31s]\n",
      "[Epoch 52/200] [D loss:0.577555] [G loss: 1.125783]          [Elapsed time: 669.66s]\n",
      "[Epoch 53/200] [D loss:0.482084] [G loss: 1.223098]          [Elapsed time: 682.10s]\n",
      "[Epoch 54/200] [D loss:0.520149] [G loss: 0.992303]          [Elapsed time: 694.54s]\n",
      "[Epoch 55/200] [D loss:0.539481] [G loss: 1.240389]          [Elapsed time: 706.95s]\n",
      "[Epoch 56/200] [D loss:0.534434] [G loss: 1.187858]          [Elapsed time: 719.35s]\n",
      "[Epoch 57/200] [D loss:0.568398] [G loss: 1.085379]          [Elapsed time: 731.72s]\n",
      "[Epoch 58/200] [D loss:0.498792] [G loss: 1.161014]          [Elapsed time: 744.09s]\n",
      "[Epoch 59/200] [D loss:0.612265] [G loss: 1.110234]          [Elapsed time: 756.46s]\n",
      "[Epoch 60/200] [D loss:0.453690] [G loss: 1.362419]          [Elapsed time: 768.94s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 61/200] [D loss:0.525302] [G loss: 1.220754]          [Elapsed time: 781.38s]\n",
      "[Epoch 62/200] [D loss:0.569081] [G loss: 0.938063]          [Elapsed time: 793.92s]\n",
      "[Epoch 63/200] [D loss:0.574880] [G loss: 0.948002]          [Elapsed time: 806.28s]\n",
      "[Epoch 64/200] [D loss:0.578731] [G loss: 1.063787]          [Elapsed time: 819.19s]\n",
      "[Epoch 65/200] [D loss:0.585555] [G loss: 1.020115]          [Elapsed time: 832.53s]\n",
      "[Epoch 66/200] [D loss:0.627692] [G loss: 1.270781]          [Elapsed time: 845.88s]\n",
      "[Epoch 67/200] [D loss:0.648786] [G loss: 1.090072]          [Elapsed time: 858.84s]\n",
      "[Epoch 68/200] [D loss:0.585760] [G loss: 1.099650]          [Elapsed time: 871.50s]\n",
      "[Epoch 69/200] [D loss:0.612383] [G loss: 0.900670]          [Elapsed time: 883.96s]\n",
      "[Epoch 70/200] [D loss:0.531239] [G loss: 1.213755]          [Elapsed time: 896.38s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 71/200] [D loss:0.520247] [G loss: 1.423194]          [Elapsed time: 908.90s]\n",
      "[Epoch 72/200] [D loss:0.607985] [G loss: 0.931105]          [Elapsed time: 921.43s]\n",
      "[Epoch 73/200] [D loss:0.541656] [G loss: 1.013569]          [Elapsed time: 933.97s]\n",
      "[Epoch 74/200] [D loss:0.500768] [G loss: 1.196907]          [Elapsed time: 946.41s]\n",
      "[Epoch 75/200] [D loss:0.560683] [G loss: 1.022557]          [Elapsed time: 958.78s]\n",
      "[Epoch 76/200] [D loss:0.536793] [G loss: 1.052979]          [Elapsed time: 971.14s]\n",
      "[Epoch 77/200] [D loss:0.531004] [G loss: 1.076694]          [Elapsed time: 983.46s]\n",
      "[Epoch 78/200] [D loss:0.568113] [G loss: 1.062961]          [Elapsed time: 995.82s]\n",
      "[Epoch 79/200] [D loss:0.563576] [G loss: 1.034487]          [Elapsed time: 1008.30s]\n",
      "[Epoch 80/200] [D loss:0.572879] [G loss: 1.103772]          [Elapsed time: 1020.72s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 81/200] [D loss:0.607532] [G loss: 1.081749]          [Elapsed time: 1033.15s]\n",
      "[Epoch 82/200] [D loss:0.598864] [G loss: 0.971372]          [Elapsed time: 1045.45s]\n",
      "[Epoch 83/200] [D loss:0.572560] [G loss: 1.285477]          [Elapsed time: 1057.76s]\n",
      "[Epoch 84/200] [D loss:0.579039] [G loss: 1.101063]          [Elapsed time: 1070.10s]\n",
      "[Epoch 85/200] [D loss:0.576080] [G loss: 1.032108]          [Elapsed time: 1082.49s]\n",
      "[Epoch 86/200] [D loss:0.614456] [G loss: 1.104042]          [Elapsed time: 1094.89s]\n",
      "[Epoch 87/200] [D loss:0.666118] [G loss: 1.032497]          [Elapsed time: 1107.30s]\n",
      "[Epoch 88/200] [D loss:0.508343] [G loss: 1.023598]          [Elapsed time: 1119.62s]\n",
      "[Epoch 89/200] [D loss:0.627612] [G loss: 0.984146]          [Elapsed time: 1131.96s]\n",
      "[Epoch 90/200] [D loss:0.620542] [G loss: 1.242597]          [Elapsed time: 1144.25s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 91/200] [D loss:0.513102] [G loss: 1.326295]          [Elapsed time: 1156.66s]\n",
      "[Epoch 92/200] [D loss:0.671573] [G loss: 1.039810]          [Elapsed time: 1169.06s]\n",
      "[Epoch 93/200] [D loss:0.635930] [G loss: 0.931301]          [Elapsed time: 1181.50s]\n",
      "[Epoch 94/200] [D loss:0.585920] [G loss: 1.011748]          [Elapsed time: 1193.93s]\n",
      "[Epoch 95/200] [D loss:0.614102] [G loss: 1.397058]          [Elapsed time: 1206.25s]\n",
      "[Epoch 96/200] [D loss:0.564961] [G loss: 1.152931]          [Elapsed time: 1218.60s]\n",
      "[Epoch 97/200] [D loss:0.533351] [G loss: 1.068661]          [Elapsed time: 1230.94s]\n",
      "[Epoch 98/200] [D loss:0.633738] [G loss: 0.911021]          [Elapsed time: 1243.35s]\n",
      "[Epoch 99/200] [D loss:0.536441] [G loss: 1.158465]          [Elapsed time: 1255.77s]\n",
      "[Epoch 100/200] [D loss:0.669310] [G loss: 0.920601]          [Elapsed time: 1268.21s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 101/200] [D loss:0.672772] [G loss: 1.008202]          [Elapsed time: 1280.54s]\n",
      "[Epoch 102/200] [D loss:0.583026] [G loss: 1.316429]          [Elapsed time: 1292.86s]\n",
      "[Epoch 103/200] [D loss:0.499070] [G loss: 1.161161]          [Elapsed time: 1305.19s]\n",
      "[Epoch 104/200] [D loss:0.585949] [G loss: 1.014325]          [Elapsed time: 1317.62s]\n",
      "[Epoch 105/200] [D loss:0.593440] [G loss: 1.109885]          [Elapsed time: 1330.04s]\n",
      "[Epoch 106/200] [D loss:0.629966] [G loss: 1.037110]          [Elapsed time: 1342.49s]\n",
      "[Epoch 107/200] [D loss:0.631504] [G loss: 1.205827]          [Elapsed time: 1354.88s]\n",
      "[Epoch 108/200] [D loss:0.624144] [G loss: 0.970693]          [Elapsed time: 1367.25s]\n",
      "[Epoch 109/200] [D loss:0.671336] [G loss: 0.886530]          [Elapsed time: 1379.52s]\n",
      "[Epoch 110/200] [D loss:0.629111] [G loss: 0.976935]          [Elapsed time: 1391.90s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 111/200] [D loss:0.606234] [G loss: 0.912885]          [Elapsed time: 1404.36s]\n",
      "[Epoch 112/200] [D loss:0.564085] [G loss: 1.032423]          [Elapsed time: 1416.72s]\n",
      "[Epoch 113/200] [D loss:0.597103] [G loss: 0.882196]          [Elapsed time: 1429.10s]\n",
      "[Epoch 114/200] [D loss:0.592840] [G loss: 0.947655]          [Elapsed time: 1441.40s]\n",
      "[Epoch 115/200] [D loss:0.512926] [G loss: 1.188357]          [Elapsed time: 1453.75s]\n",
      "[Epoch 116/200] [D loss:0.607521] [G loss: 0.996154]          [Elapsed time: 1466.09s]\n",
      "[Epoch 117/200] [D loss:0.685876] [G loss: 0.900667]          [Elapsed time: 1478.47s]\n",
      "[Epoch 118/200] [D loss:0.574561] [G loss: 1.202195]          [Elapsed time: 1490.88s]\n",
      "[Epoch 119/200] [D loss:0.602997] [G loss: 0.955681]          [Elapsed time: 1503.27s]\n",
      "[Epoch 120/200] [D loss:0.536084] [G loss: 1.241848]          [Elapsed time: 1515.61s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 121/200] [D loss:0.588984] [G loss: 1.158625]          [Elapsed time: 1527.92s]\n",
      "[Epoch 122/200] [D loss:0.586397] [G loss: 1.094384]          [Elapsed time: 1540.22s]\n",
      "[Epoch 123/200] [D loss:0.582084] [G loss: 1.096981]          [Elapsed time: 1552.62s]\n",
      "[Epoch 124/200] [D loss:0.573740] [G loss: 1.125036]          [Elapsed time: 1565.03s]\n",
      "[Epoch 125/200] [D loss:0.675055] [G loss: 1.070282]          [Elapsed time: 1577.43s]\n",
      "[Epoch 126/200] [D loss:0.602266] [G loss: 0.999184]          [Elapsed time: 1589.80s]\n",
      "[Epoch 127/200] [D loss:0.595359] [G loss: 0.899838]          [Elapsed time: 1602.10s]\n",
      "[Epoch 128/200] [D loss:0.540244] [G loss: 0.960223]          [Elapsed time: 1614.43s]\n",
      "[Epoch 129/200] [D loss:0.542985] [G loss: 1.175094]          [Elapsed time: 1626.82s]\n",
      "[Epoch 130/200] [D loss:0.462618] [G loss: 1.251979]          [Elapsed time: 1639.23s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 131/200] [D loss:0.680656] [G loss: 1.051119]          [Elapsed time: 1651.63s]\n",
      "[Epoch 132/200] [D loss:0.606269] [G loss: 0.924678]          [Elapsed time: 1663.99s]\n",
      "[Epoch 133/200] [D loss:0.680075] [G loss: 1.073253]          [Elapsed time: 1676.28s]\n",
      "[Epoch 134/200] [D loss:0.598139] [G loss: 0.993933]          [Elapsed time: 1688.60s]\n",
      "[Epoch 135/200] [D loss:0.601882] [G loss: 1.042501]          [Elapsed time: 1700.90s]\n",
      "[Epoch 136/200] [D loss:0.614667] [G loss: 0.987722]          [Elapsed time: 1713.30s]\n",
      "[Epoch 137/200] [D loss:0.682989] [G loss: 1.029211]          [Elapsed time: 1725.64s]\n",
      "[Epoch 138/200] [D loss:0.551719] [G loss: 0.991800]          [Elapsed time: 1738.01s]\n",
      "[Epoch 139/200] [D loss:0.585474] [G loss: 0.913678]          [Elapsed time: 1750.31s]\n",
      "[Epoch 140/200] [D loss:0.486724] [G loss: 1.021611]          [Elapsed time: 1762.64s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 141/200] [D loss:0.586995] [G loss: 0.864779]          [Elapsed time: 1774.90s]\n",
      "[Epoch 142/200] [D loss:0.673765] [G loss: 0.848288]          [Elapsed time: 1787.23s]\n",
      "[Epoch 143/200] [D loss:0.553766] [G loss: 0.889539]          [Elapsed time: 1799.62s]\n",
      "[Epoch 144/200] [D loss:0.577351] [G loss: 0.943338]          [Elapsed time: 1812.01s]\n",
      "[Epoch 145/200] [D loss:0.550368] [G loss: 1.009907]          [Elapsed time: 1824.36s]\n",
      "[Epoch 146/200] [D loss:0.530196] [G loss: 1.162555]          [Elapsed time: 1836.88s]\n",
      "[Epoch 147/200] [D loss:0.632846] [G loss: 1.028764]          [Elapsed time: 1849.69s]\n",
      "[Epoch 148/200] [D loss:0.615439] [G loss: 0.992590]          [Elapsed time: 1862.48s]\n",
      "[Epoch 149/200] [D loss:0.718852] [G loss: 0.997030]          [Elapsed time: 1875.87s]\n",
      "[Epoch 150/200] [D loss:0.635451] [G loss: 0.999705]          [Elapsed time: 1888.75s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 151/200] [D loss:0.615273] [G loss: 1.083176]          [Elapsed time: 1901.53s]\n",
      "[Epoch 152/200] [D loss:0.666822] [G loss: 1.100895]          [Elapsed time: 1914.58s]\n",
      "[Epoch 153/200] [D loss:0.604867] [G loss: 1.002524]          [Elapsed time: 1927.27s]\n",
      "[Epoch 154/200] [D loss:0.725837] [G loss: 0.791031]          [Elapsed time: 1939.68s]\n",
      "[Epoch 155/200] [D loss:0.624485] [G loss: 1.025415]          [Elapsed time: 1952.10s]\n",
      "[Epoch 156/200] [D loss:0.638018] [G loss: 0.886462]          [Elapsed time: 1964.49s]\n",
      "[Epoch 157/200] [D loss:0.640429] [G loss: 0.801509]          [Elapsed time: 1976.91s]\n",
      "[Epoch 158/200] [D loss:0.702544] [G loss: 0.742392]          [Elapsed time: 1989.22s]\n",
      "[Epoch 159/200] [D loss:0.609215] [G loss: 0.913785]          [Elapsed time: 2001.73s]\n",
      "[Epoch 160/200] [D loss:0.621041] [G loss: 0.871340]          [Elapsed time: 2014.27s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 161/200] [D loss:0.604764] [G loss: 0.942191]          [Elapsed time: 2026.66s]\n",
      "[Epoch 162/200] [D loss:0.578900] [G loss: 1.027530]          [Elapsed time: 2039.09s]\n",
      "[Epoch 163/200] [D loss:0.618297] [G loss: 0.801332]          [Elapsed time: 2051.54s]\n",
      "[Epoch 164/200] [D loss:0.554381] [G loss: 0.902711]          [Elapsed time: 2063.91s]\n",
      "[Epoch 165/200] [D loss:0.630620] [G loss: 0.950634]          [Elapsed time: 2076.27s]\n",
      "[Epoch 166/200] [D loss:0.628180] [G loss: 1.067981]          [Elapsed time: 2088.57s]\n",
      "[Epoch 167/200] [D loss:0.645083] [G loss: 0.934362]          [Elapsed time: 2100.92s]\n",
      "[Epoch 168/200] [D loss:0.674782] [G loss: 0.851862]          [Elapsed time: 2113.35s]\n",
      "[Epoch 169/200] [D loss:0.643003] [G loss: 0.877696]          [Elapsed time: 2125.77s]\n",
      "[Epoch 170/200] [D loss:0.629572] [G loss: 0.981300]          [Elapsed time: 2138.17s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 171/200] [D loss:0.505502] [G loss: 1.249707]          [Elapsed time: 2150.57s]\n",
      "[Epoch 172/200] [D loss:0.670664] [G loss: 0.836154]          [Elapsed time: 2162.92s]\n",
      "[Epoch 173/200] [D loss:0.568904] [G loss: 1.068264]          [Elapsed time: 2175.36s]\n",
      "[Epoch 174/200] [D loss:0.617117] [G loss: 0.827672]          [Elapsed time: 2187.76s]\n",
      "[Epoch 175/200] [D loss:0.627305] [G loss: 0.902057]          [Elapsed time: 2200.24s]\n",
      "[Epoch 176/200] [D loss:0.556446] [G loss: 0.985336]          [Elapsed time: 2212.64s]\n",
      "[Epoch 177/200] [D loss:0.668612] [G loss: 0.862313]          [Elapsed time: 2224.98s]\n",
      "[Epoch 178/200] [D loss:0.662045] [G loss: 0.946686]          [Elapsed time: 2237.26s]\n",
      "[Epoch 179/200] [D loss:0.632315] [G loss: 0.865562]          [Elapsed time: 2249.59s]\n",
      "[Epoch 180/200] [D loss:0.578882] [G loss: 0.860674]          [Elapsed time: 2262.00s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 181/200] [D loss:0.618397] [G loss: 0.887709]          [Elapsed time: 2274.44s]\n",
      "[Epoch 182/200] [D loss:0.592510] [G loss: 1.101470]          [Elapsed time: 2286.89s]\n",
      "[Epoch 183/200] [D loss:0.636655] [G loss: 0.967130]          [Elapsed time: 2299.26s]\n",
      "[Epoch 184/200] [D loss:0.689322] [G loss: 0.829239]          [Elapsed time: 2311.58s]\n",
      "[Epoch 185/200] [D loss:0.619812] [G loss: 0.876650]          [Elapsed time: 2323.98s]\n",
      "[Epoch 186/200] [D loss:0.664631] [G loss: 0.824444]          [Elapsed time: 2336.31s]\n",
      "[Epoch 187/200] [D loss:0.556028] [G loss: 1.145558]          [Elapsed time: 2348.71s]\n",
      "[Epoch 188/200] [D loss:0.653290] [G loss: 0.873948]          [Elapsed time: 2361.15s]\n",
      "[Epoch 189/200] [D loss:0.637636] [G loss: 0.980303]          [Elapsed time: 2373.58s]\n",
      "[Epoch 190/200] [D loss:0.671423] [G loss: 0.972827]          [Elapsed time: 2385.91s]\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "[Epoch 191/200] [D loss:0.728046] [G loss: 1.150129]          [Elapsed time: 2398.23s]\n",
      "[Epoch 192/200] [D loss:0.627962] [G loss: 0.928768]          [Elapsed time: 2410.53s]\n",
      "[Epoch 193/200] [D loss:0.655043] [G loss: 0.809499]          [Elapsed time: 2422.88s]\n",
      "[Epoch 194/200] [D loss:0.618178] [G loss: 0.977626]          [Elapsed time: 2435.30s]\n",
      "[Epoch 195/200] [D loss:0.675864] [G loss: 0.878031]          [Elapsed time: 2447.79s]\n",
      "[Epoch 196/200] [D loss:0.666051] [G loss: 0.794328]          [Elapsed time: 2460.25s]\n",
      "[Epoch 197/200] [D loss:0.680457] [G loss: 0.935773]          [Elapsed time: 2472.59s]\n",
      "[Epoch 198/200] [D loss:0.681239] [G loss: 0.832905]          [Elapsed time: 2484.91s]\n",
      "[Epoch 199/200] [D loss:0.590521] [G loss: 0.911992]          [Elapsed time: 2497.24s]\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY_NAME = \"./ConditionalGAN_Result_label_fix_ver\"\n",
    "if not os.path.exists(DIRECTORY_NAME):\n",
    "    os.makedirs(DIRECTORY_NAME)\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    #print('Starting epoch {}...'.format(epoch+1))\n",
    "    for i,(images,labels) in enumerate(data_loader):\n",
    "        real_imgs = images.to(DEVICE)\n",
    "        real_labels = labels.to(DEVICE)\n",
    "\n",
    "        discriminator_label = torch.cuda.FloatTensor(BATCH_SIZE,1).fill_(1.0)\n",
    "        generator_label =torch.cuda.FloatTensor(BATCH_SIZE,1).fill_(0.0)\n",
    "        # discriminator Train \n",
    "        d_optimizer.zero_grad()\n",
    "        real_validity = discriminator(real_imgs,real_labels)\n",
    "        D_loss = adversarial_loss(real_validity,discriminator_label)\n",
    "\n",
    "        latent_vector = torch.normal(mean = 0,std =1,size=(BATCH_SIZE,LATENT_DIM)).to(DEVICE)\n",
    "        fake_labels = torch.LongTensor(np.random.randint(0,class_num,BATCH_SIZE)).to(DEVICE)\n",
    "\n",
    "        fake_images = generator(latent_vector,real_labels)\n",
    "        #print(fake_images.size())\n",
    "        G_loss = adversarial_loss(discriminator(fake_images.detach(),real_labels),generator_label)\n",
    "\n",
    "        t_loss = (D_loss + G_loss) /2 \n",
    "        t_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        fake_images = generator(latent_vector,real_labels)\n",
    "        G_loss = adversarial_loss(discriminator(fake_images,real_labels),discriminator_label)\n",
    "        G_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        done = epoch* len(data_loader)+i\n",
    "        if done % 12000 == 0:\n",
    "            save_image(fake_images.data[:9],f\"{DIRECTORY_NAME}/{epoch}_epoch.png\",nrow = 3,normalize = True)\n",
    "\n",
    "    generator.eval()\n",
    "\n",
    "    print(f\"[Epoch {epoch}/{EPOCHS}] [D loss:{t_loss.item():.6f}] [G loss: {G_loss.item():.6f}]\\\n",
    "          [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
    "    if epoch % 10 == 0:\n",
    "        latent_vector = torch.normal(mean = 0,std =1,size=(class_num-1,LATENT_DIM)).to(DEVICE)\n",
    "        labels =torch.LongTensor(np.arange(0,class_num-1)).to(DEVICE) # 0~9까지 순차적으로 형성된 라벨 \n",
    "        sample_images = generator(latent_vector, labels).data.cpu()\n",
    "        print(labels)\n",
    "        save_image(sample_images.data[:],f\"{DIRECTORY_NAME}/{epoch}_epoch.png\",nrow = 3,normalize = True)\n",
    "\n",
    "# fake_label을 전혀 사용하지 않고 대신 실제 라벨을 넘겨주는 걸로 변경 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
