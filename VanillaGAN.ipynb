{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sim2real\\AppData\\Local\\miniconda3\\envs\\fish\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time \n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "from  torchinfo import summary \n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device cuda\n"
     ]
    }
   ],
   "source": [
    "# setting \n",
    "EPOCHS = 200 \n",
    "BATCH_SIZE = 100 \n",
    "LEARNING_RATE = 0.0002\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_CHANNEL = 1 \n",
    "LATENT_DIM = 100 # 28*28 = 784가 아닌데?\n",
    "\n",
    "DIRECTORY_NAME = \"./VanillaGAN_Result\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device {DEVICE}\")\n",
    "# Result Directory \n",
    "if not os.path.exists(DIRECTORY_NAME):\n",
    "    os.makedirs(DIRECTORY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator \n",
    "\n",
    "- input : (BATCH,IMAGE_CHANNEL,IMAGE_SIZE,IMAGE_SIZE)\n",
    "- output : (BATCH,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Discriminator                            [100, 1]                  --\n",
       "├─Sequential: 1-1                        [100, 1]                  --\n",
       "│    └─Linear: 2-1                       [100, 512]                401,920\n",
       "│    └─LeakyReLU: 2-2                    [100, 512]                --\n",
       "│    └─Linear: 2-3                       [100, 256]                131,328\n",
       "│    └─LeakyReLU: 2-4                    [100, 256]                --\n",
       "│    └─Linear: 2-5                       [100, 1]                  257\n",
       "│    └─Sigmoid: 2-6                      [100, 1]                  --\n",
       "==========================================================================================\n",
       "Total params: 533,505\n",
       "Trainable params: 533,505\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 53.35\n",
       "==========================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 0.62\n",
       "Params size (MB): 2.13\n",
       "Estimated Total Size (MB): 3.06\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(IMAGE_CHANNEL* IMAGE_SIZE*IMAGE_SIZE,512),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1), # []\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,img):\n",
    "        flattend = img.view(img.size(0),-1)\n",
    "        output = self.model(flattend)\n",
    "        return output \n",
    "\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "summary(discriminator,input_size=(BATCH_SIZE,IMAGE_CHANNEL,IMAGE_SIZE,IMAGE_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]         401,920\n",
      "         LeakyReLU-2                  [-1, 512]               0\n",
      "            Linear-3                  [-1, 256]         131,328\n",
      "         LeakyReLU-4                  [-1, 256]               0\n",
      "            Linear-5                    [-1, 1]             257\n",
      "           Sigmoid-6                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 2.04\n",
      "Estimated Total Size (MB): 2.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(discriminator,(IMAGE_CHANNEL,IMAGE_SIZE,IMAGE_SIZE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator \n",
    "\n",
    "- input : (BATCH,LATENT_DIM)\n",
    "- output : (BATCH,IMAGE_CHANNEL,IMAGE_SIZE,IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Generator                                [100, 1, 28, 28]          --\n",
       "├─Sequential: 1-1                        [100, 784]                --\n",
       "│    └─Linear: 2-1                       [100, 128]                12,928\n",
       "│    └─LeakyReLU: 2-2                    [100, 128]                --\n",
       "│    └─Linear: 2-3                       [100, 256]                33,024\n",
       "│    └─BatchNorm1d: 2-4                  [100, 256]                512\n",
       "│    └─LeakyReLU: 2-5                    [100, 256]                --\n",
       "│    └─Linear: 2-6                       [100, 512]                131,584\n",
       "│    └─BatchNorm1d: 2-7                  [100, 512]                1,024\n",
       "│    └─LeakyReLU: 2-8                    [100, 512]                --\n",
       "│    └─Linear: 2-9                       [100, 1024]               525,312\n",
       "│    └─BatchNorm1d: 2-10                 [100, 1024]               2,048\n",
       "│    └─LeakyReLU: 2-11                   [100, 1024]               --\n",
       "│    └─Linear: 2-12                      [100, 784]                803,600\n",
       "│    └─Tanh: 2-13                        [100, 784]                --\n",
       "==========================================================================================\n",
       "Total params: 1,510,032\n",
       "Trainable params: 1,510,032\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 151.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.04\n",
       "Forward/backward pass size (MB): 3.60\n",
       "Params size (MB): 6.04\n",
       "Estimated Total Size (MB): 9.68\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(LATENT_DIM,128), # 100,100 -==\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(128,256),\n",
    "            nn.BatchNorm1d(256,0.8),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(256,512),\n",
    "            nn.BatchNorm1d(512,0.8),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.BatchNorm1d(1024,0.8),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(1024,IMAGE_CHANNEL*IMAGE_SIZE*IMAGE_SIZE),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self,z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0),1,28,28)\n",
    "        return img \n",
    "\n",
    "generator = Generator().to(DEVICE)\n",
    "summary(generator,input_size=(BATCH_SIZE,LATENT_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data path: ./dataset/Fashion-MNIST/fashion-mnist_train.csv\n",
      "Valid data path: ./dataset/Fashion-MNIST/fashion-mnist_test.csv\n",
      "Image size: (60000, 28, 28)\n",
      "--- Label ---\n",
      "label\n",
      "2    6000\n",
      "9    6000\n",
      "6    6000\n",
      "0    6000\n",
      "3    6000\n",
      "4    6000\n",
      "5    6000\n",
      "8    6000\n",
      "7    6000\n",
      "1    6000\n",
      "Name: count, dtype: int64\n",
      "<PIL.Image.Image image mode=L size=28x28 at 0x20DD5998A30>\n",
      "Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "train_data_path = './dataset/Fashion-MNIST/fashion-mnist_train.csv' # Path of data\n",
    "valid_data_path = './dataset/Fashion-MNIST/fashion-mnist_test.csv' # Path of data\n",
    "print('Train data path:', train_data_path)\n",
    "print('Valid data path:', valid_data_path)\n",
    "\n",
    "class_list = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_num = len(class_list)\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "\n",
    "class FashionMNIST(Dataset):\n",
    "    def __init__(self, path, img_size, transform=None):\n",
    "        self.transform = transform\n",
    "        fashion_df = pd.read_csv(path)\n",
    "        self.images = fashion_df.iloc[:, 1:].values.astype('uint8').reshape(-1, img_size, img_size)\n",
    "        self.labels = fashion_df.label.values\n",
    "        print('Image size:', self.images.shape)\n",
    "        print('--- Label ---')\n",
    "        print(fashion_df.label.value_counts())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = self.images[idx]\n",
    "        img = Image.fromarray(self.images[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "\n",
    "\n",
    "dataset = FashionMNIST(train_data_path, IMAGE_SIZE,transform=None)\n",
    "imshow(dataset[1][0])\n",
    "print(dataset[1][0])\n",
    "print(class_list[dataset[1][1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (60000, 28, 28)\n",
      "--- Label ---\n",
      "label\n",
      "2    6000\n",
      "9    6000\n",
      "6    6000\n",
      "0    6000\n",
      "3    6000\n",
      "4    6000\n",
      "5    6000\n",
      "8    6000\n",
      "7    6000\n",
      "1    6000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = FashionMNIST(train_data_path,IMAGE_SIZE,transform=transforms_train)\n",
    "data_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader) # 데이터 총 수량 / BATSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss:0.379486]         [G loss: 2.136411]         [Elapsed time: 12.60s]\n",
      "[Epoch 1/200] [D loss:0.096349]         [G loss: 4.374273]         [Elapsed time: 25.40s]\n",
      "[Epoch 2/200] [D loss:0.017351]         [G loss: 9.176032]         [Elapsed time: 37.90s]\n",
      "[Epoch 3/200] [D loss:0.025360]         [G loss: 10.052016]         [Elapsed time: 50.52s]\n",
      "[Epoch 4/200] [D loss:0.118798]         [G loss: 5.993961]         [Elapsed time: 63.21s]\n",
      "[Epoch 5/200] [D loss:0.140056]         [G loss: 9.236523]         [Elapsed time: 75.74s]\n",
      "[Epoch 6/200] [D loss:0.029998]         [G loss: 7.728452]         [Elapsed time: 88.19s]\n",
      "[Epoch 7/200] [D loss:0.140664]         [G loss: 5.843629]         [Elapsed time: 100.59s]\n",
      "[Epoch 8/200] [D loss:0.102927]         [G loss: 7.308156]         [Elapsed time: 113.08s]\n",
      "[Epoch 9/200] [D loss:0.078909]         [G loss: 6.148420]         [Elapsed time: 125.73s]\n",
      "[Epoch 10/200] [D loss:0.188452]         [G loss: 5.925086]         [Elapsed time: 138.36s]\n",
      "[Epoch 11/200] [D loss:0.067643]         [G loss: 5.566268]         [Elapsed time: 150.89s]\n",
      "[Epoch 12/200] [D loss:0.046639]         [G loss: 6.437872]         [Elapsed time: 163.40s]\n",
      "[Epoch 13/200] [D loss:0.055591]         [G loss: 7.136319]         [Elapsed time: 175.79s]\n",
      "[Epoch 14/200] [D loss:0.066771]         [G loss: 12.989494]         [Elapsed time: 188.42s]\n",
      "[Epoch 15/200] [D loss:0.125535]         [G loss: 8.616027]         [Elapsed time: 201.09s]\n",
      "[Epoch 16/200] [D loss:0.160996]         [G loss: 4.574136]         [Elapsed time: 213.73s]\n",
      "[Epoch 17/200] [D loss:0.154179]         [G loss: 5.019758]         [Elapsed time: 226.29s]\n",
      "[Epoch 18/200] [D loss:0.210039]         [G loss: 4.913751]         [Elapsed time: 238.76s]\n",
      "[Epoch 19/200] [D loss:0.324974]         [G loss: 4.244746]         [Elapsed time: 251.33s]\n",
      "[Epoch 20/200] [D loss:0.431114]         [G loss: 3.662437]         [Elapsed time: 264.18s]\n",
      "[Epoch 21/200] [D loss:0.191826]         [G loss: 3.836470]         [Elapsed time: 276.77s]\n",
      "[Epoch 22/200] [D loss:0.387387]         [G loss: 3.926358]         [Elapsed time: 289.32s]\n",
      "[Epoch 23/200] [D loss:0.383532]         [G loss: 2.926345]         [Elapsed time: 301.87s]\n",
      "[Epoch 24/200] [D loss:0.207898]         [G loss: 3.585587]         [Elapsed time: 314.64s]\n",
      "[Epoch 25/200] [D loss:0.159533]         [G loss: 4.906173]         [Elapsed time: 327.24s]\n",
      "[Epoch 26/200] [D loss:0.207389]         [G loss: 2.747054]         [Elapsed time: 339.78s]\n",
      "[Epoch 27/200] [D loss:0.222423]         [G loss: 2.866179]         [Elapsed time: 352.16s]\n",
      "[Epoch 28/200] [D loss:0.355300]         [G loss: 2.715536]         [Elapsed time: 365.32s]\n",
      "[Epoch 29/200] [D loss:0.422437]         [G loss: 2.479554]         [Elapsed time: 378.14s]\n",
      "[Epoch 30/200] [D loss:0.221577]         [G loss: 2.734465]         [Elapsed time: 391.01s]\n",
      "[Epoch 31/200] [D loss:0.248659]         [G loss: 3.757767]         [Elapsed time: 403.70s]\n",
      "[Epoch 32/200] [D loss:0.419980]         [G loss: 1.760580]         [Elapsed time: 416.19s]\n",
      "[Epoch 33/200] [D loss:0.236176]         [G loss: 2.963139]         [Elapsed time: 428.65s]\n",
      "[Epoch 34/200] [D loss:0.387982]         [G loss: 2.149519]         [Elapsed time: 441.40s]\n",
      "[Epoch 35/200] [D loss:0.407944]         [G loss: 2.095618]         [Elapsed time: 454.09s]\n",
      "[Epoch 36/200] [D loss:0.301526]         [G loss: 2.313890]         [Elapsed time: 466.80s]\n",
      "[Epoch 37/200] [D loss:0.224229]         [G loss: 3.032741]         [Elapsed time: 479.30s]\n",
      "[Epoch 38/200] [D loss:0.261708]         [G loss: 2.824738]         [Elapsed time: 491.78s]\n",
      "[Epoch 39/200] [D loss:0.343588]         [G loss: 3.093509]         [Elapsed time: 504.17s]\n",
      "[Epoch 40/200] [D loss:0.339719]         [G loss: 2.314776]         [Elapsed time: 516.68s]\n",
      "[Epoch 41/200] [D loss:0.361356]         [G loss: 1.749240]         [Elapsed time: 529.18s]\n",
      "[Epoch 42/200] [D loss:0.569750]         [G loss: 1.593596]         [Elapsed time: 541.64s]\n",
      "[Epoch 43/200] [D loss:0.371419]         [G loss: 2.344898]         [Elapsed time: 554.10s]\n",
      "[Epoch 44/200] [D loss:0.309103]         [G loss: 2.246433]         [Elapsed time: 566.65s]\n",
      "[Epoch 45/200] [D loss:0.536754]         [G loss: 1.736412]         [Elapsed time: 579.46s]\n",
      "[Epoch 46/200] [D loss:0.335606]         [G loss: 2.173071]         [Elapsed time: 592.10s]\n",
      "[Epoch 47/200] [D loss:0.495207]         [G loss: 1.270782]         [Elapsed time: 604.41s]\n",
      "[Epoch 48/200] [D loss:0.515610]         [G loss: 2.356941]         [Elapsed time: 616.74s]\n",
      "[Epoch 49/200] [D loss:0.468509]         [G loss: 1.687490]         [Elapsed time: 629.31s]\n",
      "[Epoch 50/200] [D loss:0.527436]         [G loss: 1.923109]         [Elapsed time: 641.88s]\n",
      "[Epoch 51/200] [D loss:0.317927]         [G loss: 1.938441]         [Elapsed time: 654.54s]\n",
      "[Epoch 52/200] [D loss:0.377721]         [G loss: 2.228150]         [Elapsed time: 667.06s]\n",
      "[Epoch 53/200] [D loss:0.412509]         [G loss: 2.192528]         [Elapsed time: 679.44s]\n",
      "[Epoch 54/200] [D loss:0.332579]         [G loss: 2.167192]         [Elapsed time: 691.60s]\n",
      "[Epoch 55/200] [D loss:0.478043]         [G loss: 1.357620]         [Elapsed time: 703.77s]\n",
      "[Epoch 56/200] [D loss:0.597996]         [G loss: 1.408108]         [Elapsed time: 716.05s]\n",
      "[Epoch 57/200] [D loss:0.511856]         [G loss: 1.636145]         [Elapsed time: 728.75s]\n",
      "[Epoch 58/200] [D loss:0.408339]         [G loss: 1.777827]         [Elapsed time: 741.26s]\n",
      "[Epoch 59/200] [D loss:0.447458]         [G loss: 1.402092]         [Elapsed time: 753.93s]\n",
      "[Epoch 60/200] [D loss:0.416342]         [G loss: 1.504393]         [Elapsed time: 766.44s]\n",
      "[Epoch 61/200] [D loss:0.413094]         [G loss: 1.343074]         [Elapsed time: 778.96s]\n",
      "[Epoch 62/200] [D loss:0.537534]         [G loss: 1.759686]         [Elapsed time: 791.57s]\n",
      "[Epoch 63/200] [D loss:0.627579]         [G loss: 1.455238]         [Elapsed time: 804.02s]\n",
      "[Epoch 64/200] [D loss:0.487677]         [G loss: 1.362466]         [Elapsed time: 816.34s]\n",
      "[Epoch 65/200] [D loss:0.472009]         [G loss: 1.044267]         [Elapsed time: 828.89s]\n",
      "[Epoch 66/200] [D loss:0.560780]         [G loss: 1.329464]         [Elapsed time: 841.48s]\n",
      "[Epoch 67/200] [D loss:0.527341]         [G loss: 1.611496]         [Elapsed time: 854.05s]\n",
      "[Epoch 68/200] [D loss:0.462573]         [G loss: 1.321420]         [Elapsed time: 866.75s]\n",
      "[Epoch 69/200] [D loss:0.464682]         [G loss: 1.175545]         [Elapsed time: 879.04s]\n",
      "[Epoch 70/200] [D loss:0.506040]         [G loss: 1.295889]         [Elapsed time: 891.53s]\n",
      "[Epoch 71/200] [D loss:0.535001]         [G loss: 1.261512]         [Elapsed time: 903.83s]\n",
      "[Epoch 72/200] [D loss:0.548533]         [G loss: 1.512770]         [Elapsed time: 916.35s]\n",
      "[Epoch 73/200] [D loss:0.535533]         [G loss: 1.498930]         [Elapsed time: 928.75s]\n",
      "[Epoch 74/200] [D loss:0.626171]         [G loss: 0.935528]         [Elapsed time: 941.02s]\n",
      "[Epoch 75/200] [D loss:0.491986]         [G loss: 1.322900]         [Elapsed time: 953.28s]\n",
      "[Epoch 76/200] [D loss:0.612803]         [G loss: 1.130735]         [Elapsed time: 965.44s]\n",
      "[Epoch 77/200] [D loss:0.563262]         [G loss: 1.105825]         [Elapsed time: 977.76s]\n",
      "[Epoch 78/200] [D loss:0.574510]         [G loss: 1.162217]         [Elapsed time: 990.39s]\n",
      "[Epoch 79/200] [D loss:0.688801]         [G loss: 1.124528]         [Elapsed time: 1003.08s]\n",
      "[Epoch 80/200] [D loss:0.513369]         [G loss: 1.284702]         [Elapsed time: 1015.64s]\n",
      "[Epoch 81/200] [D loss:0.623083]         [G loss: 1.126698]         [Elapsed time: 1028.28s]\n",
      "[Epoch 82/200] [D loss:0.553472]         [G loss: 1.502650]         [Elapsed time: 1040.53s]\n",
      "[Epoch 83/200] [D loss:0.559752]         [G loss: 1.177179]         [Elapsed time: 1053.28s]\n",
      "[Epoch 84/200] [D loss:0.528164]         [G loss: 1.120470]         [Elapsed time: 1066.05s]\n",
      "[Epoch 85/200] [D loss:0.703351]         [G loss: 1.150440]         [Elapsed time: 1078.83s]\n",
      "[Epoch 86/200] [D loss:0.619234]         [G loss: 1.132842]         [Elapsed time: 1091.42s]\n",
      "[Epoch 87/200] [D loss:0.538733]         [G loss: 0.960081]         [Elapsed time: 1103.77s]\n",
      "[Epoch 88/200] [D loss:0.482054]         [G loss: 1.470860]         [Elapsed time: 1116.48s]\n",
      "[Epoch 89/200] [D loss:0.707499]         [G loss: 1.172047]         [Elapsed time: 1129.02s]\n",
      "[Epoch 90/200] [D loss:0.607692]         [G loss: 0.973125]         [Elapsed time: 1141.50s]\n",
      "[Epoch 91/200] [D loss:0.522031]         [G loss: 1.231921]         [Elapsed time: 1153.99s]\n",
      "[Epoch 92/200] [D loss:0.532660]         [G loss: 1.175980]         [Elapsed time: 1166.65s]\n",
      "[Epoch 93/200] [D loss:0.603567]         [G loss: 1.034200]         [Elapsed time: 1179.26s]\n",
      "[Epoch 94/200] [D loss:0.513185]         [G loss: 1.313380]         [Elapsed time: 1191.65s]\n",
      "[Epoch 95/200] [D loss:0.623415]         [G loss: 1.171351]         [Elapsed time: 1203.91s]\n",
      "[Epoch 96/200] [D loss:0.479143]         [G loss: 1.327651]         [Elapsed time: 1216.45s]\n",
      "[Epoch 97/200] [D loss:0.644388]         [G loss: 1.145995]         [Elapsed time: 1228.98s]\n",
      "[Epoch 98/200] [D loss:0.571496]         [G loss: 1.209232]         [Elapsed time: 1241.43s]\n",
      "[Epoch 99/200] [D loss:0.567180]         [G loss: 1.067659]         [Elapsed time: 1254.04s]\n",
      "[Epoch 100/200] [D loss:0.425629]         [G loss: 1.327302]         [Elapsed time: 1266.67s]\n",
      "[Epoch 101/200] [D loss:0.590473]         [G loss: 1.365998]         [Elapsed time: 1279.32s]\n",
      "[Epoch 102/200] [D loss:0.620073]         [G loss: 1.168911]         [Elapsed time: 1291.94s]\n",
      "[Epoch 103/200] [D loss:0.559661]         [G loss: 1.013521]         [Elapsed time: 1304.25s]\n",
      "[Epoch 104/200] [D loss:0.580123]         [G loss: 1.151097]         [Elapsed time: 1316.53s]\n",
      "[Epoch 105/200] [D loss:0.622455]         [G loss: 1.026500]         [Elapsed time: 1328.67s]\n",
      "[Epoch 106/200] [D loss:0.540163]         [G loss: 1.106059]         [Elapsed time: 1341.10s]\n",
      "[Epoch 107/200] [D loss:0.564331]         [G loss: 0.962842]         [Elapsed time: 1353.52s]\n",
      "[Epoch 108/200] [D loss:0.529944]         [G loss: 1.290455]         [Elapsed time: 1366.00s]\n",
      "[Epoch 109/200] [D loss:0.630528]         [G loss: 0.985914]         [Elapsed time: 1378.40s]\n",
      "[Epoch 110/200] [D loss:0.576156]         [G loss: 1.163245]         [Elapsed time: 1390.82s]\n",
      "[Epoch 111/200] [D loss:0.611614]         [G loss: 1.114987]         [Elapsed time: 1403.26s]\n",
      "[Epoch 112/200] [D loss:0.587802]         [G loss: 1.118633]         [Elapsed time: 1415.79s]\n",
      "[Epoch 113/200] [D loss:0.647427]         [G loss: 1.035394]         [Elapsed time: 1428.43s]\n",
      "[Epoch 114/200] [D loss:0.493210]         [G loss: 1.257037]         [Elapsed time: 1440.97s]\n",
      "[Epoch 115/200] [D loss:0.589271]         [G loss: 0.980888]         [Elapsed time: 1453.70s]\n",
      "[Epoch 116/200] [D loss:0.616871]         [G loss: 1.070783]         [Elapsed time: 1466.27s]\n",
      "[Epoch 117/200] [D loss:0.529138]         [G loss: 1.311424]         [Elapsed time: 1478.76s]\n",
      "[Epoch 118/200] [D loss:0.568471]         [G loss: 1.168213]         [Elapsed time: 1491.16s]\n",
      "[Epoch 119/200] [D loss:0.575341]         [G loss: 1.129827]         [Elapsed time: 1503.32s]\n",
      "[Epoch 120/200] [D loss:0.589748]         [G loss: 0.976578]         [Elapsed time: 1515.58s]\n",
      "[Epoch 121/200] [D loss:0.581915]         [G loss: 1.372605]         [Elapsed time: 1528.04s]\n",
      "[Epoch 122/200] [D loss:0.621336]         [G loss: 1.203081]         [Elapsed time: 1540.20s]\n",
      "[Epoch 123/200] [D loss:0.587550]         [G loss: 1.072871]         [Elapsed time: 1552.36s]\n",
      "[Epoch 124/200] [D loss:0.659347]         [G loss: 1.038612]         [Elapsed time: 1564.51s]\n",
      "[Epoch 125/200] [D loss:0.635675]         [G loss: 0.981445]         [Elapsed time: 1576.65s]\n",
      "[Epoch 126/200] [D loss:0.527856]         [G loss: 1.321771]         [Elapsed time: 1588.85s]\n",
      "[Epoch 127/200] [D loss:0.603586]         [G loss: 0.890774]         [Elapsed time: 1600.96s]\n",
      "[Epoch 128/200] [D loss:0.519153]         [G loss: 1.296150]         [Elapsed time: 1613.10s]\n",
      "[Epoch 129/200] [D loss:0.575813]         [G loss: 1.024208]         [Elapsed time: 1625.28s]\n",
      "[Epoch 130/200] [D loss:0.591102]         [G loss: 0.980280]         [Elapsed time: 1637.40s]\n",
      "[Epoch 131/200] [D loss:0.549954]         [G loss: 1.034045]         [Elapsed time: 1649.50s]\n",
      "[Epoch 132/200] [D loss:0.560598]         [G loss: 1.091717]         [Elapsed time: 1661.56s]\n",
      "[Epoch 133/200] [D loss:0.510292]         [G loss: 1.139047]         [Elapsed time: 1673.67s]\n",
      "[Epoch 134/200] [D loss:0.625574]         [G loss: 0.958978]         [Elapsed time: 1685.80s]\n",
      "[Epoch 135/200] [D loss:0.552513]         [G loss: 1.384246]         [Elapsed time: 1697.94s]\n",
      "[Epoch 136/200] [D loss:0.624955]         [G loss: 1.129871]         [Elapsed time: 1710.05s]\n",
      "[Epoch 137/200] [D loss:0.568031]         [G loss: 1.159428]         [Elapsed time: 1722.29s]\n",
      "[Epoch 138/200] [D loss:0.578439]         [G loss: 1.113382]         [Elapsed time: 1734.43s]\n",
      "[Epoch 139/200] [D loss:0.543203]         [G loss: 1.093500]         [Elapsed time: 1746.56s]\n",
      "[Epoch 140/200] [D loss:0.573056]         [G loss: 1.004735]         [Elapsed time: 1758.75s]\n",
      "[Epoch 141/200] [D loss:0.629060]         [G loss: 1.092113]         [Elapsed time: 1770.99s]\n",
      "[Epoch 142/200] [D loss:0.552367]         [G loss: 1.020542]         [Elapsed time: 1783.22s]\n",
      "[Epoch 143/200] [D loss:0.594167]         [G loss: 1.092404]         [Elapsed time: 1795.45s]\n",
      "[Epoch 144/200] [D loss:0.614364]         [G loss: 1.125467]         [Elapsed time: 1807.82s]\n",
      "[Epoch 145/200] [D loss:0.619295]         [G loss: 1.021982]         [Elapsed time: 1820.01s]\n",
      "[Epoch 146/200] [D loss:0.640344]         [G loss: 1.031342]         [Elapsed time: 1832.16s]\n",
      "[Epoch 147/200] [D loss:0.611310]         [G loss: 1.111895]         [Elapsed time: 1844.33s]\n",
      "[Epoch 148/200] [D loss:0.569831]         [G loss: 1.116559]         [Elapsed time: 1856.51s]\n",
      "[Epoch 149/200] [D loss:0.627239]         [G loss: 0.965814]         [Elapsed time: 1868.71s]\n",
      "[Epoch 150/200] [D loss:0.512408]         [G loss: 1.118852]         [Elapsed time: 1880.90s]\n",
      "[Epoch 151/200] [D loss:0.520343]         [G loss: 1.150979]         [Elapsed time: 1893.13s]\n",
      "[Epoch 152/200] [D loss:0.557198]         [G loss: 1.262281]         [Elapsed time: 1905.32s]\n",
      "[Epoch 153/200] [D loss:0.506042]         [G loss: 1.313191]         [Elapsed time: 1917.51s]\n",
      "[Epoch 154/200] [D loss:0.552571]         [G loss: 1.479827]         [Elapsed time: 1929.71s]\n",
      "[Epoch 155/200] [D loss:0.641790]         [G loss: 0.985463]         [Elapsed time: 1941.90s]\n",
      "[Epoch 156/200] [D loss:0.559289]         [G loss: 1.075061]         [Elapsed time: 1954.17s]\n",
      "[Epoch 157/200] [D loss:0.645884]         [G loss: 0.931815]         [Elapsed time: 1966.37s]\n",
      "[Epoch 158/200] [D loss:0.679257]         [G loss: 0.886344]         [Elapsed time: 1978.61s]\n",
      "[Epoch 159/200] [D loss:0.550505]         [G loss: 1.115023]         [Elapsed time: 1990.76s]\n",
      "[Epoch 160/200] [D loss:0.651486]         [G loss: 1.004842]         [Elapsed time: 2002.86s]\n",
      "[Epoch 161/200] [D loss:0.651795]         [G loss: 0.957251]         [Elapsed time: 2014.95s]\n",
      "[Epoch 162/200] [D loss:0.598323]         [G loss: 1.142033]         [Elapsed time: 2027.03s]\n",
      "[Epoch 163/200] [D loss:0.608012]         [G loss: 1.087684]         [Elapsed time: 2039.20s]\n",
      "[Epoch 164/200] [D loss:0.542389]         [G loss: 1.161321]         [Elapsed time: 2051.38s]\n",
      "[Epoch 165/200] [D loss:0.576201]         [G loss: 0.991014]         [Elapsed time: 2063.51s]\n",
      "[Epoch 166/200] [D loss:0.640290]         [G loss: 0.977297]         [Elapsed time: 2075.63s]\n",
      "[Epoch 167/200] [D loss:0.546631]         [G loss: 1.146025]         [Elapsed time: 2087.70s]\n",
      "[Epoch 168/200] [D loss:0.539321]         [G loss: 1.186997]         [Elapsed time: 2099.84s]\n",
      "[Epoch 169/200] [D loss:0.608045]         [G loss: 1.065818]         [Elapsed time: 2111.97s]\n",
      "[Epoch 170/200] [D loss:0.540963]         [G loss: 1.189243]         [Elapsed time: 2124.12s]\n",
      "[Epoch 171/200] [D loss:0.605905]         [G loss: 1.111815]         [Elapsed time: 2136.23s]\n",
      "[Epoch 172/200] [D loss:0.601397]         [G loss: 1.154728]         [Elapsed time: 2148.38s]\n",
      "[Epoch 173/200] [D loss:0.540593]         [G loss: 1.383898]         [Elapsed time: 2160.51s]\n",
      "[Epoch 174/200] [D loss:0.606230]         [G loss: 0.942427]         [Elapsed time: 2172.60s]\n",
      "[Epoch 175/200] [D loss:0.570670]         [G loss: 1.221882]         [Elapsed time: 2184.68s]\n",
      "[Epoch 176/200] [D loss:0.642277]         [G loss: 0.933966]         [Elapsed time: 2196.76s]\n",
      "[Epoch 177/200] [D loss:0.676098]         [G loss: 0.968476]         [Elapsed time: 2208.86s]\n",
      "[Epoch 178/200] [D loss:0.690428]         [G loss: 1.299529]         [Elapsed time: 2221.00s]\n",
      "[Epoch 179/200] [D loss:0.644713]         [G loss: 1.018325]         [Elapsed time: 2233.11s]\n",
      "[Epoch 180/200] [D loss:0.559716]         [G loss: 1.102595]         [Elapsed time: 2245.27s]\n",
      "[Epoch 181/200] [D loss:0.532623]         [G loss: 1.118498]         [Elapsed time: 2257.40s]\n",
      "[Epoch 182/200] [D loss:0.572946]         [G loss: 1.069250]         [Elapsed time: 2269.48s]\n",
      "[Epoch 183/200] [D loss:0.694162]         [G loss: 1.009751]         [Elapsed time: 2281.59s]\n",
      "[Epoch 184/200] [D loss:0.635656]         [G loss: 0.817807]         [Elapsed time: 2293.68s]\n",
      "[Epoch 185/200] [D loss:0.565849]         [G loss: 1.146754]         [Elapsed time: 2305.83s]\n",
      "[Epoch 186/200] [D loss:0.585082]         [G loss: 1.130626]         [Elapsed time: 2317.98s]\n",
      "[Epoch 187/200] [D loss:0.632085]         [G loss: 1.096431]         [Elapsed time: 2330.08s]\n",
      "[Epoch 188/200] [D loss:0.546881]         [G loss: 1.165715]         [Elapsed time: 2342.19s]\n",
      "[Epoch 189/200] [D loss:0.629484]         [G loss: 1.019760]         [Elapsed time: 2354.33s]\n",
      "[Epoch 190/200] [D loss:0.593671]         [G loss: 1.037020]         [Elapsed time: 2366.43s]\n",
      "[Epoch 191/200] [D loss:0.701718]         [G loss: 0.975725]         [Elapsed time: 2378.47s]\n",
      "[Epoch 192/200] [D loss:0.651876]         [G loss: 1.030730]         [Elapsed time: 2390.66s]\n",
      "[Epoch 193/200] [D loss:0.649412]         [G loss: 0.943747]         [Elapsed time: 2402.78s]\n",
      "[Epoch 194/200] [D loss:0.585482]         [G loss: 1.016245]         [Elapsed time: 2414.89s]\n",
      "[Epoch 195/200] [D loss:0.569108]         [G loss: 1.115620]         [Elapsed time: 2427.03s]\n",
      "[Epoch 196/200] [D loss:0.727381]         [G loss: 0.922834]         [Elapsed time: 2439.13s]\n",
      "[Epoch 197/200] [D loss:0.663968]         [G loss: 1.101968]         [Elapsed time: 2451.20s]\n",
      "[Epoch 198/200] [D loss:0.613038]         [G loss: 0.875657]         [Elapsed time: 2463.29s]\n",
      "[Epoch 199/200] [D loss:0.652011]         [G loss: 1.042866]         [Elapsed time: 2475.41s]\n"
     ]
    }
   ],
   "source": [
    "# GAN \n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    #print('Starting epoch {}...'.format(epoch+1))\n",
    "    for i,(images,_) in enumerate(data_loader):\n",
    "        real_imgs = images.to(DEVICE)\n",
    "        \n",
    "        discriminator_label = torch.ones(BATCH_SIZE).unsqueeze(1).to(DEVICE)\n",
    "        generator_label = torch.zeros(BATCH_SIZE).unsqueeze(1).to(DEVICE)\n",
    "        \n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "        latent = torch.normal(mean=0,std=1,size=(BATCH_SIZE,LATENT_DIM)).to(DEVICE)\n",
    "        fake_images = generator(latent)\n",
    "        d_loss = adversarial_loss(discriminator(real_imgs),discriminator_label)\n",
    "        g_loss = adversarial_loss(discriminator(fake_images.detach()),generator_label)\n",
    "\n",
    "        t_loss = (d_loss + g_loss) /2\n",
    "        t_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        fake_images = generator(latent)\n",
    "        g_loss = adversarial_loss(discriminator(fake_images),discriminator_label)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        done = epoch* len(data_loader)+i\n",
    "        if done % 12000 == 0:\n",
    "            save_image(fake_images.data[:9],f\"{DIRECTORY_NAME}/{epoch}_epoch.png\",nrow = 3,normalize = True)\n",
    "\n",
    "    print(f\"[Epoch {epoch}/{EPOCHS}] [D loss:{t_loss.item():.6f}] \\\n",
    "        [G loss: {g_loss.item():.6f}] \\\n",
    "        [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cGAN \n",
    "# for epoch in range(EPOCHS):\n",
    "#     print('Starting epoch {}...'.format(epoch+1))\n",
    "#     for i,(images,labels) in enumerate(data_loader):\n",
    "#         real_imgs = images.to(DEVICE)\n",
    "#         real_labels = labels.to(DEVICE)\n",
    "\n",
    "#         discriminator_label = torch.cuda.FloatTensor(BATCH_SIZE,1).fill_(1.0)\n",
    "#         generator_label =torch.cuda.FloatTensor(BATCH_SIZE,1).fill_(0.0)\n",
    "#         # discriminator Train \n",
    "#         d_optimizer.zero_grad()\n",
    "#         real_validity = discriminator(real_imgs,real_labels)\n",
    "#         D_loss = adversarial_loss(real_validity,discriminator_label)\n",
    "\n",
    "#         latent_vector = torch.normal(mean = 0,std =1,size=(BATCH_SIZE,LATENT_DIM)).to(DEVICE)\n",
    "#         fake_labels = torch.LongTensor(np.random.randint(0,class_num,BATCH_SIZE)).to(DEVICE)\n",
    "\n",
    "#         fake_images = generator(latent_vector,fake_labels)\n",
    "\n",
    "#         # generator Train \n",
    "#         g_optimizer.zero_grad()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
